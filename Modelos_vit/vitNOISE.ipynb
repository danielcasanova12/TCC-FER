{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "def save_model(model, optimizer, path: str, epoch: int):\n",
    "\n",
    "    # Salvar o estado do modelo e do otimizador junto com a época\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, path)\n",
    "    print(f\"Modelo e estado salvos em: {path}\")\n",
    "\n",
    "def load_model(model, optimizer, path: str):\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"O arquivo {path} não foi encontrado.\")\n",
    "    \n",
    "    # Carregar o estado salvo\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "    print(f\"Modelo carregado de: {path}\")\n",
    "    print(f\"Época carregada: {epoch}\")\n",
    "    \n",
    "    return model, optimizer, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\" NoisyNN in PyTorch\n",
    "\n",
    "'NoisyNN: Exploring the Influence of Information Entropy Change in Learning Systems'\n",
    "- https://arxiv.org/pdf/2309.10625v2.pdf\n",
    "\n",
    "Note that it's not an official implementation\n",
    "\"\"\"\n",
    "import torch\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "\n",
    "def quality_matrix(k, alpha=0.3):\n",
    "    \"\"\"r\n",
    "    Quality matrix Q. Described in the eq (17) so that eps = QX, where X is the input. \n",
    "    Alpha is 0.3, as mentioned in Appendix D.\n",
    "    \"\"\"\n",
    "    identity = torch.diag(torch.ones(k))\n",
    "    shift_identity = torch.zeros(k, k)\n",
    "    for i in range(k):\n",
    "        shift_identity[(i+1)%k, i] = 1\n",
    "    opt = -alpha * identity + alpha * shift_identity\n",
    "    return opt\n",
    "\n",
    "def optimal_quality_matrix(k):\n",
    "    \"\"\"r\n",
    "    Optimal Quality matrix Q. Described in the eq (19) so that eps = QX, where X is the input. \n",
    "    Suppose 1_(kxk) is torch.ones\n",
    "    \"\"\"\n",
    "    return torch.diag(torch.ones(k)) * -k/(k+1) + torch.ones(k, k) / (k+1)\n",
    "\n",
    "class NoisyViT(VisionTransformer):\n",
    "    \"\"\"r\n",
    "    Args:\n",
    "        optimal: Determine the linear transform noise is produced by the quality matrix or the optimal quality matrix.\n",
    "        res: Inference resolution. Ensure the aspect ratio = 1\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, optimal: bool, res: int, **kwargs):\n",
    "        self.stage3_res = res // 16\n",
    "        if optimal:\n",
    "            linear_transform_noise = optimal_quality_matrix(self.stage3_res)\n",
    "        else:\n",
    "            linear_transform_noise = quality_matrix(self.stage3_res)\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear_transform_noise = torch.nn.Parameter(linear_transform_noise, requires_grad=False)\n",
    "\n",
    "    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.grad_checkpointing and not torch.jit.is_scripting():\n",
    "            return super().forward_features(x)\n",
    "        \n",
    "        x = self.patch_embed(x)\n",
    "        x = self._pos_embed(x)\n",
    "        x = self.patch_drop(x)\n",
    "        x = self.norm_pre(x)\n",
    "        # Add noise when training/testing\n",
    "        # See https://openreview.net/forum?id=Ce0dDt9tUT for more detail\n",
    "        x = self.blocks[:-1](x)\n",
    "        # Suppose the token dim = 1\n",
    "        token = x[:, 0, :].unsqueeze(1)\n",
    "        x = x[:, 1:, :].permute(0, 2, 1)\n",
    "        B, C, L = x.shape\n",
    "        x = x.reshape(B, C, self.stage3_res, self.stage3_res)\n",
    "        x = self.linear_transform_noise@x + x\n",
    "        x = x.flatten(2).transpose(1, 2).contiguous()\n",
    "        x = torch.cat([token, x], dim=1)\n",
    "        x = self.blocks[-1](x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# We don't specify more args because the paper didn't reveal more details\n",
    "def vit_t(optimal=True, res=224) -> NoisyViT:\n",
    "    model = NoisyViT(\n",
    "        optimal=optimal, \n",
    "        res=res, \n",
    "        patch_size=4, \n",
    "        embed_dim=192, \n",
    "        depth=12, \n",
    "        num_heads=3\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def vit_s(optimal=True, res=224) -> NoisyViT:\n",
    "    model = NoisyViT(\n",
    "        optimal=optimal, \n",
    "        res=res, \n",
    "        patch_size=4, \n",
    "        embed_dim=384, \n",
    "        depth=12, \n",
    "        num_heads=6\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def vit_b(optimal=True, res=224) -> NoisyViT:\n",
    "    model = NoisyViT(\n",
    "        optimal=optimal, \n",
    "        res=res, \n",
    "        patch_size=4, \n",
    "        embed_dim=768, \n",
    "        depth=12, \n",
    "        num_heads=12\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def vit_l(optimal=True, res=224) -> NoisyViT:\n",
    "    model = NoisyViT(\n",
    "        optimal=optimal, \n",
    "        res=res, \n",
    "        patch_size=16, \n",
    "        embed_dim=1024, \n",
    "        depth=24, \n",
    "        num_heads=16\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Easy test\n",
    "# if __name__ == '__main__':\n",
    "#     model = vit_l().cuda()\n",
    "#     inputs = torch.rand((2, 3, 224, 224)).cuda()\n",
    "#     output = model(inputs)\n",
    "#     print('Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum modelo salvo encontrado. Iniciando do zero.\n",
      "Época 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando:   0%|          | 0/3589 [00:00<?, ?it/s]c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\timm\\models\\vision_transformer.py:93: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  x = F.scaled_dot_product_attention(\n",
      "Treinando: 100%|██████████| 3589/3589 [7:02:04<00:00,  7.06s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino - Loss: 7.5230, Acc: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validando: 100%|██████████| 449/449 [03:29<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação - Loss: 7.5285, Acc: 0.00%\n",
      "Modelo e estado salvos em: noisy_vit.pth\n",
      "Época 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando:  52%|█████▏    | 1878/3589 [4:06:01<2:58:43,  6.27s/it] "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Configurar transformações para treino e validação\n",
    "transformacoes_de_imagens = {\n",
    "    'treino': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224), scale=(0.05, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]),\n",
    "    'validacao': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Carregar datasets Fer-2013\n",
    "dataset = '../data/Fer-2013'\n",
    "pasta_treino = os.path.join(dataset, 'treino')\n",
    "pasta_validacao = os.path.join(dataset, 'validacao')\n",
    "\n",
    "data = {\n",
    "    'treino': datasets.ImageFolder(root=pasta_treino, transform=transformacoes_de_imagens['treino']),\n",
    "    'validacao': datasets.ImageFolder(root=pasta_validacao, transform=transformacoes_de_imagens['validacao'])\n",
    "}\n",
    "\n",
    "# Criar DataLoaders\n",
    "batch_size = 8\n",
    "data_loader_treino = DataLoader(data['treino'], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "data_loader_validacao = DataLoader(data['validacao'], batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Verificar dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Função de treinamento para NoisyViT\n",
    "def train_noisy_vit(model, epochs=10, lr=1e-4, weight_decay=1e-4, save_path=\"noisy_vit.pth\",resume=True):\n",
    "    # Configurar otimizador, scheduler e função de perda\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = CosineLRScheduler(optimizer, t_initial=epochs, lr_min=1e-6, warmup_t=2)\n",
    "    loss_fn = LabelSmoothingCrossEntropy(0.1)\n",
    "\n",
    "    model.to(device)\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        try:\n",
    "            model, optimizer, start_epoch = load_model(model, optimizer, save_path)\n",
    "            print(f\"Retomando o treinamento a partir da época {start_epoch + 1}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Nenhum modelo salvo encontrado. Iniciando do zero.\")    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        print(f\"Época {epoch + 1}/{epochs}\")\n",
    "        for inputs, labels in tqdm(data_loader_treino, desc=\"Treinando\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_acc = 100. * correct / total\n",
    "        print(f\"Treino - Loss: {train_loss / len(data_loader_treino):.4f}, Acc: {train_acc:.2f}%\")\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(data_loader_validacao, desc=\"Validando\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100. * correct / total\n",
    "        print(f\"Validação - Loss: {val_loss / len(data_loader_validacao):.4f}, Acc: {val_acc:.2f}%\")\n",
    "        save_model(model, optimizer, save_path, epoch=epoch + 1)\n",
    "        scheduler.step(epoch + 1)\n",
    "\n",
    "# Treinar NoisyViT\n",
    "if __name__ == '__main__':\n",
    "    # Criar o modelo NoisyViT\n",
    "    \n",
    "    model = vit_l()  # Escolha do modelo: vit_t, vit_s, vit_b, vit_l\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    train_noisy_vit(model, epochs=10, lr=1e-4, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Configurações\n",
    "batch_size = 8  # Reduzido para evitar OOM\n",
    "epochs = 10\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# Transformações\n",
    "transformacoes_de_imagens = {\n",
    "    'treino': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224), scale=(0.05, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]),\n",
    "    'validacao': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Dataset\n",
    "dataset = '../data/Fer-2013'\n",
    "pasta_treino = os.path.join(dataset, 'treino')\n",
    "pasta_validacao = os.path.join(dataset, 'validacao')\n",
    "\n",
    "data = {\n",
    "    'treino': datasets.ImageFolder(root=pasta_treino, transform=transformacoes_de_imagens['treino']),\n",
    "    'validacao': datasets.ImageFolder(root=pasta_validacao, transform=transformacoes_de_imagens['validacao'])\n",
    "}\n",
    "\n",
    "data_loader_treino = DataLoader(data['treino'], batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "data_loader_validacao = DataLoader(data['validacao'], batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Verificar dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Função de Treinamento\n",
    "def train_noisy_vit(model, epochs, lr, weight_decay):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = CosineLRScheduler(optimizer, t_initial=epochs, lr_min=1e-6, warmup_t=2)\n",
    "    loss_fn = LabelSmoothingCrossEntropy(0.1)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()  # Mixed Precision\n",
    "    model.to(device)\n",
    "    model.set_grad_checkpointing(enable=True)  # Ativar Gradient Checkpointing\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        print(f\"Época {epoch + 1}/{epochs}\")\n",
    "        for inputs, labels in tqdm(data_loader_treino, desc=\"Treinando\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():  # Mixed Precision\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "        print(f\"Treino - Loss: {train_loss / len(data_loader_treino):.4f}, Acc: {train_acc:.2f}%\")\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(data_loader_validacao, desc=\"Validando\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100. * correct / total\n",
    "        print(f\"Validação - Loss: {val_loss / len(data_loader_validacao):.4f}, Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        scheduler.step(epoch + 1)\n",
    "\n",
    "# Treinar o modelo\n",
    "if __name__ == '__main__': # Altere para o modelo menor\n",
    "    model = vit_t()  # Escolha um modelo menor para evitar OOM\n",
    "    train_noisy_vit(model, epochs=epochs, lr=lr, weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
